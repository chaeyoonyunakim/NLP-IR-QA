{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdtRZlqDGxddB+FjO8wc3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyoonyunakim/NLP-IR-QA/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6KLY3vxp15Xh",
        "outputId": "8fdf4bc0-d0d6-4564-b659-d88b7c4bbe1a"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lUXi4rCI2Qzb",
        "outputId": "26476559-d9a4-4b6c-f3f1-c07b293c6d73"
      },
      "source": [
        "%ls -l \"/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 3601280 Feb 23  2021 '/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THji5Cj_2rMB"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyG2VFkZ2w94"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DeVDlbiE2ypH",
        "outputId": "e823ea18-12f3-461f-eeef-97a5d924a6ca"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "set(stopwords.words('english'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v7bhgDWl9aUg",
        "outputId": "cd39f0df-3d38-4e7e-e525-d8582920eac6"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re7UB28r2z-P"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwTe9wMf3MpC"
      },
      "source": [
        "## Tabular representation of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "N1GxpONV3AD5",
        "outputId": "1e6a0e1f-b030-4311-a1d6-6ef6b700b7e0"
      },
      "source": [
        "df = pd.read_json('/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json')\n",
        "df.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dbpedia_1177</td>\n",
              "      <td>Was Jacqueline Kennedy Onassis a follower of M...</td>\n",
              "      <td>boolean</td>\n",
              "      <td>[boolean]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dbpedia_14427</td>\n",
              "      <td>What is the name of the opera based on Twelfth...</td>\n",
              "      <td>resource</td>\n",
              "      <td>[dbo:Opera, dbo:MusicalWork, dbo:Work]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dbpedia_16615</td>\n",
              "      <td>When did Lena Horne receive the Grammy Award f...</td>\n",
              "      <td>literal</td>\n",
              "      <td>[date]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ...                                    type\n",
              "0   dbpedia_1177  ...                               [boolean]\n",
              "1  dbpedia_14427  ...  [dbo:Opera, dbo:MusicalWork, dbo:Work]\n",
              "2  dbpedia_16615  ...                                  [date]\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QgeZu4bD3JXL",
        "outputId": "07f89485-73d7-4aa5-9988-c638f6af4d75"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17571, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LJCtM3Ip3MEq",
        "outputId": "abc7b241-e14e-4c97-fa41-c5b54efbb36e"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "question    43\n",
              "category     0\n",
              "type         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V2MxRjfm3St2",
        "outputId": "906c6fb7-9aa4-49fd-9935-255258afe151"
      },
      "source": [
        "df.dropna(subset=['id', 'question'], inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17528, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0tHSOBT3Uh8"
      },
      "source": [
        "text = df.question.values\n",
        "#testdata = text.tolist()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rt-yXdpb3W4-",
        "outputId": "439e4432-3346-43cb-f218-e5f7eed1e251"
      },
      "source": [
        "text"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Was Jacqueline Kennedy Onassis a follower of Melkite Greek Catholic Church?',\n",
              "       'What is the name of the opera based on Twelfth Night ?',\n",
              "       'When did Lena Horne receive the Grammy Award for Best Jazz Vocal Album?',\n",
              "       ...,\n",
              "       'Who replaced Charles Evans Hughes as the Chief Justice of The United States?',\n",
              "       'Name the river with source as Columbia Lake and river mouth is located in Clatsop Country ?',\n",
              "       'When will Selma Lagerl√∂f start their membership in the Free-minded National Association?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4r_1h6Pa3YS0",
        "outputId": "33da80d2-160f-4060-be13-4d9cba398946"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17528"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4T9qTH3din"
      },
      "source": [
        "## 1. Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivRZUexQ3ayX"
      },
      "source": [
        "# clean the corpus\n",
        "sentences = []\n",
        "vocab = []\n",
        "tokens = []\n",
        "\n",
        "for sent in text:\n",
        "    x = word_tokenize(sent)\n",
        "    sentence = [w.lower() for w in x if w.isalpha()]\n",
        "    sentences.append(sentence)\n",
        " \n",
        "    for word in sentence:\n",
        "        if word not in vocab:\n",
        "            vocab.append(word)\n",
        "            \n",
        "for word in vocab:\n",
        "    if word not in stopwords.words():\n",
        "        tokens.append(word)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRrSnzi--N7q"
      },
      "source": [
        "stem_words = []\n",
        "filtered_1 = []\n",
        "ps = PorterStemmer()\n",
        "\n",
        "for w in tokens:\n",
        "    rootWord = ps.stem(w)\n",
        "    stem_words.append(rootWord)\n",
        "    \n",
        "for word in stem_words:\n",
        "    if word not in filtered_1:\n",
        "        filtered_1.append(word)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v250SXbe-Oge"
      },
      "source": [
        "lemma_word = []\n",
        "filtered_2 = []\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for w in tokens:\n",
        "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
        "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "    lemma_word.append(word3)\n",
        "    \n",
        "for word in lemma_word:\n",
        "    if word not in filtered_2:\n",
        "        filtered_2.append(word)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI79R8Gm-VlB"
      },
      "source": [
        "# number of words in the vocab\n",
        "len_vector1 = len(filtered_1)\n",
        "len_vector2 = len(filtered_2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K0UqOGBd3hTN",
        "outputId": "f371af75-ab80-4e03-9194-7c6324554a8b"
      },
      "source": [
        "sentences[:1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['was',\n",
              "  'jacqueline',\n",
              "  'kennedy',\n",
              "  'onassis',\n",
              "  'a',\n",
              "  'follower',\n",
              "  'of',\n",
              "  'melkite',\n",
              "  'greek',\n",
              "  'catholic',\n",
              "  'church']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_R0MPUT13rqw",
        "outputId": "5e6337e4-1245-422a-a2f7-a7402195dee3"
      },
      "source": [
        "vocab[:5], len(vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['was', 'jacqueline', 'kennedy', 'onassis', 'a'], 19269)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U6aCw9EC3uyO",
        "outputId": "096ad20e-2015-449c-ff77-68551f7bd23c"
      },
      "source": [
        "tokens[:5], len(tokens)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['jacqueline', 'kennedy', 'onassis', 'follower', 'melkite'], 18905)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4hR3GhQ23vl9",
        "outputId": "2356a4f0-7a33-41f0-e6aa-24302a9768e6"
      },
      "source": [
        "filtered_1[:5], len(filtered_1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['jacquelin', 'kennedi', 'onassi', 'follow', 'melkit'], 16660)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jvCpdPte9iQC",
        "outputId": "60c8040c-a44d-4bf1-b818-4bbe775ed544"
      },
      "source": [
        "filtered_2[:5], len(filtered_2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['jacqueline', 'kennedy', 'onassis', 'follower', 'melkite'], 17350)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFfK_LIzH-gk"
      },
      "source": [
        "## 2. Assign an index to the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yGuffv-bV8"
      },
      "source": [
        "# Index dictionary to assign an index to each word in vocabulary\n",
        "index_word = {}\n",
        "i = 0\n",
        "for word in vocab:\n",
        "    index_word[word] = i \n",
        "    i += 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejM1hVDSIHw_"
      },
      "source": [
        "## 3. Define the Bag of Words model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M6NtuJeIE6p"
      },
      "source": [
        "def bag_of_words(sent):\n",
        "    count_dict = defaultdict(int)\n",
        "    vec = np.zeros(len(vocab))\n",
        "    for item in sent:\n",
        "        count_dict[item] += 1\n",
        "    for key,item in count_dict.items():\n",
        "        vec[index_word[key]] = item\n",
        "    return vec"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3j94wG9IV8T"
      },
      "source": [
        "## 4. Testing our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jIK-DxISDc"
      },
      "source": [
        "matrix = [bag_of_words(sentences[i]) for i in range(len(sentences))]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OaxV1R5-IZeY",
        "outputId": "73911411-184f-47e4-ff13-0aae162fb378"
      },
      "source": [
        "matrix = np.stack(matrix)\n",
        "matrix"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JhVS4neUJZXy",
        "outputId": "f7319974-2509-4f71-838d-d04adfa5387c"
      },
      "source": [
        "matrix.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17528, 19269)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1oM0vw0JetC"
      },
      "source": [
        "***Build a Classifier***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fWEzGcMcJb3Z",
        "outputId": "34d5e921-24ec-4ebb-a20c-fc724a38280b"
      },
      "source": [
        "testlabel = df.category.values\n",
        "len(testlabel)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17528"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872YmRSHJomK"
      },
      "source": [
        "# define the multinomial logistic regression model\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# define the model evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, matrix, testlabel, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yC1_YaD9e0tS",
        "outputId": "66c32130-3557-449d-dcc3-5a7a20bf54c6"
      },
      "source": [
        "# report the model performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.938 (0.005)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}